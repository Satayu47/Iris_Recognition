{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2681,"status":"ok","timestamp":1679880104869,"user":{"displayName":"Oranus Kotsuwan","userId":"01427927832110327372"},"user_tz":-420},"id":"ea_b4yKLxY0q"},"outputs":[],"source":["import cv2\n","import numpy as np\n","from matplotlib import pyplot as plt\n","from skimage.filters import gaussian\n","from skimage.segmentation import active_contour\n","import math\n","import imutils\n","import pandas as pd\n","import csv\n","from pathlib import Path\n","from tqdm.auto import trange, tqdm\n","from scipy import interpolate\n","from scipy.optimize import fsolve\n","# import enlighten"]},{"cell_type":"markdown","metadata":{"id":"W2MrzlLrxY0t"},"source":["## <span style=\"color:orange\">*Image Preprocessing*</span>"]},{"cell_type":"markdown","metadata":{"id":"q3ueVuN7xY0u"},"source":["### <span style=\"color:#AF7AC5\">Import Image</span>"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":335,"status":"ok","timestamp":1679880146892,"user":{"displayName":"Oranus Kotsuwan","userId":"01427927832110327372"},"user_tz":-420},"id":"6S4nBgWIxY0v"},"outputs":[],"source":["def read_image(path):\n","    \n","    img = cv2.imread(path)\n","    \n","    gray_eye_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    return gray_eye_image"]},{"cell_type":"markdown","metadata":{"id":"Axr4q8nBxY0w"},"source":["### <span style=\"color:#AF7AC5\">Iris Localization</span>"]},{"cell_type":"markdown","metadata":{"id":"MPdLWpHfxY0w"},"source":["#### Houghman Circle Detection"]},{"cell_type":"markdown","metadata":{"id":"81xaWhKExY0w"},"source":["##### Find Pupil `Slow`"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1679880154347,"user":{"displayName":"Oranus Kotsuwan","userId":"01427927832110327372"},"user_tz":-420},"id":"HZNZ1GVSxY0w"},"outputs":[],"source":["def get_edges(image):\n","        edges = cv2.Canny(image, 20, 100)\n","        kernel = np.ones((3, 3), np.uint8)\n","        edges = cv2.dilate(edges, kernel, iterations=2)\n","        # ksize = 2 * random.randrange(5, 11) + 1\n","        edges = cv2.GaussianBlur(edges, (15, 15), 0)\n","        return edges"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bP9FAQfExY0x","outputId":"9f5b531b-5905-45cc-806a-87f3a9926bb6"},"outputs":[],"source":["a = np.ones((3, 3), np.uint8)\n","print(a)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1679880157115,"user":{"displayName":"Oranus Kotsuwan","userId":"01427927832110327372"},"user_tz":-420},"id":"pmjIUAWaxY0y"},"outputs":[],"source":["def find_pupil(img):\n","    param1 = 200  # 200\n","    param2 = 120  # 150\n","    pupil_circles = []\n","    while(param2 > 35 and len(pupil_circles) < 100):\n","        for mdn, thrs in [(m, t)\n","                          for m in [3, 5, 7]\n","                          for t in [20, 25, 30, 35, 40, 45, 50, 55, 60]]:\n","            # Median Blur\n","            median = cv2.medianBlur(img, 2*mdn+1)\n","\n","            # Threshold\n","            _, thres = cv2.threshold(\n","                median, thrs, 255,\n","                cv2.THRESH_BINARY_INV)\n","\n","            # Canny Edges\n","            edges = get_edges(thres)\n","\n","            # HoughCircles\n","            circles = cv2.HoughCircles(edges, cv2.HOUGH_GRADIENT, 1, 1,\n","                                       np.array([]), param1, param2)\n","            if circles is not None:\n","                # convert the (x, y) coordinates and radius of the circles to integers\n","                circles = np.round(circles).astype(\"int\")\n","                for c in circles:\n","                    pupil_circles.append(c)\n","\n","        param2 = param2 - 10\n","\n","    cimg = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n","    \n","    if circles is None:\n","        return\n","    mean_0 = int(np.mean([c[0][0] for c in circles]))\n","    mean_1 = int(np.mean([c[0][1] for c in circles]))\n","    mean_2 = int(np.mean([c[0][2] for c in circles]))\n","\n","    return mean_0, mean_1, mean_2\n"]},{"cell_type":"markdown","metadata":{"id":"GrSgUccfxY0y"},"source":["##### Find Pupil `Fast`"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":648,"status":"ok","timestamp":1679880162201,"user":{"displayName":"Oranus Kotsuwan","userId":"01427927832110327372"},"user_tz":-420},"id":"9fDCmhYgxY0z"},"outputs":[],"source":["def find_pupil_new(img):\n","    img = cv2.medianBlur(img, 15)\n","    img = cv2.Canny(img, 0, 50)\n","    param1 = 200  # 200\n","    param2 = 120  # 150\n","    decrement = 1\n","    circles = None\n","    while circles is None and param2 > 20:\n","        # HoughCircles\n","        circles = cv2.HoughCircles(img, cv2.HOUGH_GRADIENT, 1, 1,\n","                                    param1=param1, param2=param2,\n","                                    minRadius=20, maxRadius=80)\n","\n","        if circles is not None:\n","            break\n","\n","        param2 -= decrement\n","    \n","    if circles is None:\n","        return None, None, None\n","    \n","    return circles.astype(int)[0][0]\n"]},{"cell_type":"markdown","metadata":{"id":"PLOWX2DOxY0z"},"source":["#### Localization"]},{"cell_type":"markdown","metadata":{"id":"DPcAnkCAxY0z"},"source":["##### Houghman circle with Active contour"]},{"cell_type":"markdown","metadata":{"id":"gcVR2OlVxY0z"},"source":["|`alpha`|`beta`|`gamma`|\n","|---|---|---|\n","|1.6|390|0.005|\n","|1.5|390|0.005|\n","|1.6|300|0.05|\n","|1.6|500|0.05|\n","|1.6|1000|0.05|\n","|1.45|590|0.01|"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":320,"status":"ok","timestamp":1679880165150,"user":{"displayName":"Oranus Kotsuwan","userId":"01427927832110327372"},"user_tz":-420},"id":"Aaf_81h5xY00"},"outputs":[],"source":["def localization(img, N=400, alpha=1.45, beta=590, w_line=0.01, gamma=0.01):\n","    DoG = cv2.GaussianBlur(img, (3, 3), 0) - cv2.GaussianBlur(img, (25, 25), 0)\n","    median1 = cv2.medianBlur(DoG, 9)\n","    eroted = cv2.erode(median1, np.ones((3, 3), np.uint8), iterations=1)\n","    median2 = cv2.medianBlur(eroted, 5)\n","    dilated = cv2.dilate(median2, np.ones((3, 3), np.uint8), iterations=1)\n","    eroted = cv2.erode(dilated, np.ones((5, 5), np.uint8), iterations=1)\n","    result = cv2.bitwise_or(img, eroted)\n","        \n","    x, y, rad = find_pupil_new(img)\n","    if x is None:\n","        x, y = 350, 250\n","    \n","    s = np.linspace(0, 2*np.pi, 400)\n","    c = x + 150*np.cos(s)\n","    r = y + 150*np.sin(s)\n","    init = np.array([r, c]).T\n","\n","    snake = active_contour(result, init, alpha=alpha, beta=beta, w_line=w_line, gamma=gamma)\n","    \n","    return init, snake, (x, y, rad)\n","    "]},{"cell_type":"markdown","metadata":{"id":"boXmP-YsxY00"},"source":["##### Only Active contour"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":318,"status":"ok","timestamp":1679880168121,"user":{"displayName":"Oranus Kotsuwan","userId":"01427927832110327372"},"user_tz":-420},"id":"LkTzxiNXxY00"},"outputs":[],"source":["def localization_active(img, N=400):\n","    DoG = cv2.GaussianBlur(img, (3, 3), 0) - cv2.GaussianBlur(img, (25, 25), 0)\n","    median1 = cv2.medianBlur(DoG, 9)\n","    eroted = cv2.erode(median1, np.ones((3, 3), np.uint8), iterations=1)\n","    median2 = cv2.medianBlur(eroted, 5)\n","    dilated = cv2.dilate(median2, np.ones((3, 3), np.uint8), iterations=1)\n","    eroted = cv2.erode(dilated, np.ones((5, 5), np.uint8), iterations=1)\n","    result = cv2.bitwise_or(img, eroted)\n","        \n","    s = np.linspace(0, 2*np.pi, 400)\n","    c = 350 + 200*np.cos(s)\n","    r = 250 + 200*np.sin(s)\n","\n","    init = np.array([r, c]).T\n","    \n","    temp = cv2.medianBlur(img, 15)\n","    temp = cv2.Canny(temp, 0, 20)\n","\n","    snake_pupil = active_contour(result, init, alpha=4, beta=1000, gamma=0.05)\n","    \n","    s = np.linspace(0, 2*np.pi, 400)\n","    c = 350 + 250*np.cos(s)\n","    r = 250 + 250*np.sin(s)\n","    init = np.array([r, c]).T\n","\n","    snake = active_contour(result, init, alpha=1.45, beta=590, gamma=0.05)\n","    \n","    return init, snake, snake_pupil"]},{"cell_type":"markdown","metadata":{"id":"JPjt5411xY01"},"source":["##### AI Generated Active Contours"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1679880190469,"user":{"displayName":"Oranus Kotsuwan","userId":"01427927832110327372"},"user_tz":-420},"id":"gP0HVR7oxY01"},"outputs":[],"source":["def localize_iris(iris_img):\n","  # Convert the image to grayscale\n","  gray_iris = cv2.cvtColor(iris_img, cv2.COLOR_BGR2GRAY)\n","\n","  # Apply a Gaussian blur to the image to reduce noise\n","  blurred_iris = cv2.GaussianBlur(gray_iris, (5, 5), 0)\n","\n","  # Use the Canny edge detector to find edges in the image\n","  edges = cv2.Canny(blurred_iris, 50, 150)\n","\n","  # Use the active contour algorithm (e.g. Snake) to find the iris boundary\n","  contours = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n","  contours = imutils.grab_contours(contours)\n","  contours = sorted(contours, key = cv2.contourArea, reverse = True)[:1]\n","  iris_boundary = cv2.approxPolyDP(contours[0], 0.01 * cv2.arcLength(contours[0], True), True)\n","\n","  # Use the iris boundary to crop the iris region from the image\n","  mask = np.zeros(edges.shape, dtype=np.uint8)\n","  cv2.drawContours(mask, [iris_boundary], -1, 255, -1)\n","  cropped_iris = cv2.bitwise_and(iris_img, iris_img, mask=mask)\n","\n","  # Return the resulting cropped iris image\n","  return cropped_iris"]},{"cell_type":"markdown","metadata":{"id":"UfxDfqwqxY01"},"source":["### <span style=\"color:#AF7AC5\">Iris Normalization</span>"]},{"cell_type":"markdown","metadata":{"id":"PmjgVubpxY01"},"source":["#### Circle Function"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":351,"status":"ok","timestamp":1679880195856,"user":{"displayName":"Oranus Kotsuwan","userId":"01427927832110327372"},"user_tz":-420},"id":"5Kg6uIYFxY02"},"outputs":[],"source":["def trans_axis(circle, theta):\n","\n","    x0, y0, r = circle\n","    x = int(x0 + r * math.cos(theta))\n","    y = int(y0 + r * math.sin(theta))\n","    return x, y"]},{"cell_type":"markdown","metadata":{"id":"R8K3g2lyxY02"},"source":["#### Houghman Circle with Active Contour"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":415,"status":"ok","timestamp":1679880200003,"user":{"displayName":"Oranus Kotsuwan","userId":"01427927832110327372"},"user_tz":-420},"id":"EZarNmZbxY02"},"outputs":[],"source":["def normalization(img, pupil_circle, iris_circle, M=64, N=400, offset=0):\n","\n","    normalized = np.zeros((M, N))\n","    theta = np.linspace(0, 2 * np.pi, N)\n","\n","    for i in range(N):\n","        curr_theta = theta[i] + offset\n","        if curr_theta > 2 * np.pi:\n","            curr_theta -= 2 * np.pi\n","        begin = trans_axis(pupil_circle, curr_theta)\n","        end = iris_circle\n","\n","        xspace = np.linspace(begin[0], end[i][0], M)\n","        yspace = np.linspace(begin[1], end[i][1], M)\n","        normalized[:, i] = [255 - img[int(y), int(x)]\n","                            if 0 <= int(x) < img.shape[1] and 0 <= int(y) < img.shape[0]\n","                            else 0\n","                            for x, y in zip(xspace, yspace)]\n","    return normalized"]},{"cell_type":"markdown","metadata":{"id":"ZJlqx4OCxY02"},"source":["#### Active Contour Only"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":314,"status":"ok","timestamp":1679880209025,"user":{"displayName":"Oranus Kotsuwan","userId":"01427927832110327372"},"user_tz":-420},"id":"8rR5M1fLxY03"},"outputs":[],"source":["def normalization_active(img, pupil_circle, iris_circle, M=64, N=400, offset=0):\n","\n","    normalized = np.zeros((M, N))\n","    theta = np.linspace(0, 2 * np.pi, N)\n","\n","    for i in range(N):\n","        curr_theta = theta[i] + offset\n","        if curr_theta > 2 * np.pi:\n","            curr_theta -= 2 * np.pi\n","        begin = pupil_circle\n","        end = iris_circle\n","\n","        xspace = np.linspace(begin[i][0], end[i][0], M)\n","        yspace = np.linspace(begin[i][1], end[i][1], M)\n","        normalized[:, i] = [255 - img[int(y), int(x)]\n","                            if 0 <= int(x) < img.shape[1] and 0 <= int(y) < img.shape[0]\n","                            else 0\n","                            for x, y in zip(xspace, yspace)]\n","    return normalized"]},{"cell_type":"markdown","metadata":{"id":"1LXu2Q6xxY03"},"source":["### <span style=\"color:#AF7AC5\">Eye Lash Removal</span>"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":301,"status":"ok","timestamp":1679880217454,"user":{"displayName":"Oranus Kotsuwan","userId":"01427927832110327372"},"user_tz":-420},"id":"Day21VcLxY03"},"outputs":[],"source":["def lash_removal(img, thresh=40):\n","    ref = img < thresh\n","    coords = np.where(ref == 1)\n","    rmov_img = img.astype(float)\n","    rmov_img[coords] = float('nan')\n","    return rmov_img"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1679880220664,"user":{"displayName":"Oranus Kotsuwan","userId":"01427927832110327372"},"user_tz":-420},"id":"_YLqA-QNxY03"},"outputs":[],"source":["def lash_removal_daugman(img, thresh=40):\n","    ref = img < thresh\n","    coords = np.where(ref == 1)\n","    rmov_img = img.astype(float)\n","    rmov_img[coords] = float('nan')\n","    temp_img = rmov_img.copy()\n","    temp_img[coords] = 255/2\n","    avg = np.sum(temp_img) / (rmov_img.shape[0] * rmov_img.shape[1])\n","    rmov_img[coords] = avg\n","    \n","    noise_img = np.zeros(img.shape)\n","    noise_img[coords] = 1\n","    return rmov_img, noise_img.astype(bool)"]},{"cell_type":"markdown","metadata":{"id":"pp92hdlvxY03"},"source":["## <span style=\"color:orange\">*Feature Extraction*</span>"]},{"cell_type":"markdown","metadata":{"id":"Iml1nTKYxY04"},"source":["### <span style=\"color:#AF7AC5\">Convolute with Gabor</span>"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":329,"status":"ok","timestamp":1679880233585,"user":{"displayName":"Oranus Kotsuwan","userId":"01427927832110327372"},"user_tz":-420},"id":"51O8hKiWxY04"},"outputs":[],"source":["def gaborconvolve_f(img, minw_length, mult, sigma_f):\n","    \"\"\"\n","    Convolve each row of an imgage with 1D log-Gabor filters.\n","    \"\"\"\n","    rows, ndata = img.shape\n","    logGabor_f = np.zeros(ndata)\n","    filterb = np.zeros([rows, ndata], dtype=complex)\n","\n","    radius = np.arange(ndata/2 + 1) / (ndata/2) / 2\n","    radius[0] = 1\n","\n","    # filter wavelength\n","    wavelength = minw_length\n","\n","    # radial filter component \n","    fo = 1 / wavelength\n","    logGabor_f[0: int(ndata/2) + 1] = np.exp((-(np.log(radius/fo))**2) /\n","                                    (2 * np.log(sigma_f)**2))\n","    logGabor_f[0] = 0\n","\n","    # convolution for each row \n","    # Not optimized version\n","    # for r in range(rows):\n","    #     signal = img[r, 0:ndata]\n","    #     imagefft = np.fft.fft(signal)\n","    #     filterb[r, :] = np.fft.ifft(imagefft * logGabor_f)\n","\n","    # Optimized version\n","    signals = img[:, 0:ndata]\n","    imagefft = np.fft.fft(signals, axis=1)\n","    filterb = np.fft.ifft(imagefft * logGabor_f, axis=1)\n","    \n","    return filterb"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":296,"status":"ok","timestamp":1679880235353,"user":{"displayName":"Oranus Kotsuwan","userId":"01427927832110327372"},"user_tz":-420},"id":"EWstiOHFxY04"},"outputs":[],"source":["def encode_iris(arr_polar, arr_noise, minw_length, mult, sigma_f):\n","    \"\"\"\n","    Generate iris template and noise mask from the normalised iris region.\n","    \"\"\"\n","    # convolve with gabor filters\n","    filterb = gaborconvolve_f(arr_polar, minw_length, mult, sigma_f)\n","    l = arr_polar.shape[1]\n","    template = np.zeros([arr_polar.shape[0], 2 * l])\n","    h = np.arange(arr_polar.shape[0])\n","\n","    # making the iris template\n","    mask_noise = np.zeros(template.shape)\n","    filt = filterb[:, :]\n","\n","    # quantization and check to se if the phase data is useful\n","    H1 = np.real(filt) > 0\n","    H2 = np.imag(filt) > 0\n","\n","    H3 = np.abs(filt) < 0.0001\n","    # Not optimized code\n","    for i in range(l):\n","        ja = 2 * i\n","\n","        # biometric template\n","        template[:, ja] = H1[:, i]\n","        template[:, ja + 1] = H2[:, i]\n","        # noise mask_noise\n","        mask_noise[:, ja] = arr_noise[:, i] | H3[:, i]\n","        mask_noise[:, ja + 1] = arr_noise[:, i] | H3[:, i]\n","\n","\n","    return template, mask_noise"]},{"cell_type":"markdown","metadata":{"id":"hPZ6Bsg9xY04"},"source":["## <span style=\"color:orange\">*Matching*</span>"]},{"cell_type":"markdown","metadata":{"id":"EPfu-8cvxY05"},"source":["### <span style=\"color:#AF7AC5\">Shift Bit Function</span>"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":306,"status":"ok","timestamp":1679880241228,"user":{"displayName":"Oranus Kotsuwan","userId":"01427927832110327372"},"user_tz":-420},"id":"DmdJO9aAxY05"},"outputs":[],"source":["def shiftbits_ham(template, noshifts):\n","    templatenew = np.zeros(template.shape)\n","    width = template.shape[1]\n","    s = 2 * np.abs(noshifts)\n","    p = width - s\n","\n","    if noshifts == 0:\n","        templatenew = template\n","\n","    elif noshifts < 0:\n","        x = np.arange(p)\n","        templatenew[:, x] = template[:, s + x]\n","        x = np.arange(p, width)\n","        templatenew[:, x] = template[:, x - p]\n","\n","    else:\n","        x = np.arange(s, width)\n","        templatenew[:, x] = template[:, x - s]\n","        x = np.arange(s)\n","        templatenew[:, x] = template[:, p + x]\n","\n","    return templatenew"]},{"cell_type":"markdown","metadata":{"id":"Dk7ClvTPxY06"},"source":["### <span style=\"color:#AF7AC5\">Hamming Distance</span>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Auh3yAf0xY06"},"outputs":[],"source":["# def HammingDistance(template1, mask1, template2, mask2):\n","#     hd = np.nan\n","\n","#     # Shifting template left and right, use the lowest Hamming distance\n","#     for shifts in range(-8, 9):\n","#         template1s = shiftbits_ham(template1, shifts)\n","#         mask1s = shiftbits_ham(mask1, shifts)\n","\n","#         mask = np.logical_and(mask1s, mask2)\n","#         nummaskbits = np.sum(mask == 1)\n","#         totalbits = template1s.size - nummaskbits\n","\n","#         C = np.logical_xor(template1s, template2)\n","#         C = np.logical_and(C, np.logical_not(mask))\n","#         bitsdiff = np.sum(C == 1)\n","\n","#         if totalbits == 0:\n","#             hd = np.nan\n","#         else:\n","#             hd1 = bitsdiff / totalbits\n","#             if hd1 < hd or np.isnan(hd):\n","#                 hd = hd1\n","\n","#     return hd"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":301,"status":"ok","timestamp":1679880245091,"user":{"displayName":"Oranus Kotsuwan","userId":"01427927832110327372"},"user_tz":-420},"id":"qTJwvosRxY06"},"outputs":[],"source":["def HammingDistance(template1, mask1, template2, mask2):\n","    hd = np.nan\n","\n","    bitsdiff_arr = np.empty(17, dtype=np.float64)\n","    totalbits_arr = np.empty(17, dtype=np.float64)\n","\n","    for i, shifts in enumerate(range(-8, 9)):\n","        template1s = shiftbits_ham(template1, shifts)\n","        mask1s = shiftbits_ham(mask1, shifts)\n","\n","        mask = np.logical_and(mask1s, mask2)\n","        nummaskbits = np.sum(mask == 1)\n","        totalbits_arr[i] = template1s.size - nummaskbits\n","\n","        C = np.logical_xor(template1s, template2)\n","        C = np.logical_and(C, np.logical_not(mask))\n","        bitsdiff_arr[i] = np.sum(C == 1)\n","\n","    for i, totalbits in enumerate(totalbits_arr):\n","        if totalbits == 0:\n","            hd = np.nan\n","        else:\n","            hd1 = bitsdiff_arr[i] / totalbits\n","            if hd1 < hd or np.isnan(hd):\n","                hd = hd1\n","\n","    return hd\n"]},{"cell_type":"markdown","metadata":{"id":"5yg6qyR1xY06"},"source":["## <span style=\"color:orange\">*Test Plot*</span>"]},{"cell_type":"markdown","metadata":{"id":"m9GSLbjfxY07"},"source":["### <span style=\"color:#AF7AC5\">All Image Check</span>"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":311,"status":"ok","timestamp":1679880249052,"user":{"displayName":"Oranus Kotsuwan","userId":"01427927832110327372"},"user_tz":-420},"id":"FDvjGgM-xY07"},"outputs":[],"source":["def plot_prepro(img_num1=0, img_num2=60, plot_cols=3):\n","    plot_size = 29\n","    plot_rows = math.ceil((img_num2-img_num1) / plot_cols)\n","\n","    # fig, ax = plt.subplots(plot_rows*2, plot_cols, figsize=(20, plot_size*plot_rows))\n","    fig = plt.figure(figsize=(20, plot_size*plot_rows), constrained_layout=False)\n","    outer_grid = fig.add_gridspec(plot_rows*2, plot_cols, wspace=0.1, hspace=-0.2)\n","\n","    for i in range(img_num1, img_num2):\n","        # Read image\n","        img = read_image(f'Iris-Dataset/CASIA-IrisV2/device1/00{str(i).zfill(2)}/00{str(i).zfill(2)}_000.bmp')\n","        \n","        # Image Preprocessing (Localization)\n","        init, snake, circles = localization(img)\n","        \n","        pupil_circle = circles\n","        iris_circle = np.flip(np.array(snake).astype(int), 1)\n","        \n","        # Graph of Localization\n","        x = i//plot_cols\n","        y = i-(i//plot_cols)*plot_cols\n","        \n","        inner_grid = outer_grid[x, y].subgridspec(5, 1, hspace=-0.75)\n","        ax0 = fig.add_subplot(inner_grid[0:2])\n","        ax1 = fig.add_subplot(inner_grid[3])\n","        ax2 = fig.add_subplot(inner_grid[4])\n","        \n","        ax0.imshow(img, cmap='gray')\n","        ax0.plot(snake[:, 1], snake[:, 0], '-b', lw=1)\n","        ax0.set_title(f'Image {i}')\n","        \n","        if circles[2] is None:\n","            print(f\"No circles found in image {i}\")\n","            ax1.imshow(img, cmap='gray')\n","            ax1.axis([0, 400, 64, 0])\n","            continue\n","        \n","        circle = plt.Circle((circles[0], circles[1]), circles[2], color='g', fill=False, linewidth=1)\n","        ax0.add_patch(circle)\n","        ax0.scatter(circles[0], circles[1], s=20, c='g', marker='o')\n","        \n","        # Image Preprocessing (Normalization)\n","        # With eyelashes removal\n","        iris_norm = normalization(img, pupil_circle, iris_circle)\n","        \n","        # Without eyelashes removal\n","        # iris_norm = normalization(img, pupil_circle, iris_circle)\n","        \n","        ax1.imshow(iris_norm, cmap='gray')\n","        ax1.set_title(f'Normalized Image {i}')\n","        \n","        # Feature Extraction\n","        romv_img, noise_img = lash_removal_daugman(iris_norm, thresh=50)\n","        template, mask_noise = encode_iris(romv_img, noise_img, minw_length=18, mult=1, sigma_f=0.5)\n","        \n","        ax2.imshow(template, cmap='gray')\n","        ax2.set_title(f'Binary Encoded Image {i}')\n","        \n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"t81rlWnwxY07"},"source":["### <span style=\"color:#AF7AC5\">Matching Check</span>"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":297,"status":"ok","timestamp":1679880254339,"user":{"displayName":"Oranus Kotsuwan","userId":"01427927832110327372"},"user_tz":-420},"id":"LIzGb4IixY07"},"outputs":[],"source":["def plot_matching(img_num=0, compare_num=10):\n","    plot_size = 29\n","    plot_cols = 2\n","    plot_rows = math.ceil((compare_num) / plot_cols)\n","    templates = []\n","    masks = []\n","\n","    # fig, ax = plt.subplots(plot_rows*2, plot_cols, figsize=(20, plot_size*plot_rows))\n","    fig = plt.figure(figsize=(20, plot_size*plot_rows), constrained_layout=False)\n","    outer_grid = fig.add_gridspec(plot_rows*2, plot_cols, wspace=0.1, hspace=-0.2)\n","\n","    for i in range(compare_num):\n","        # Read image\n","        img = read_image(f'Iris-Dataset/CASIA-IrisV2/device1/00{str(img_num).zfill(2)}/00{str(img_num).zfill(2)}_0{str(i).zfill(2)}.bmp')\n","        \n","        # Image Preprocessing (Localization)\n","        init, snake, circles = localization(img)\n","        \n","        pupil_circle = circles\n","        iris_circle = np.flip(np.array(snake).astype(int), 1)\n","        \n","        # Graph of Localization\n","        x = i//plot_cols\n","        y = i-(i//plot_cols)*plot_cols\n","        \n","        inner_grid = outer_grid[x, y].subgridspec(5, 1, hspace=-0.7)\n","        ax0 = fig.add_subplot(inner_grid[0:2])\n","        ax1 = fig.add_subplot(inner_grid[3])\n","        ax2 = fig.add_subplot(inner_grid[4])\n","        \n","        ax0.imshow(img, cmap='gray')\n","        ax0.plot(snake[:, 1], snake[:, 0], '-b', lw=1)\n","        ax0.set_title(f'Image {img_num}', fontsize=20)\n","        \n","        if circles[2] is None:\n","            print(f\"No circles found in image {img_num}\")\n","            ax1.imshow(img, cmap='gray')\n","            ax1.axis([0, 400, 64, 0])\n","            continue\n","        \n","        circle = plt.Circle((circles[0], circles[1]), circles[2], color='g', fill=False, linewidth=1)\n","        ax0.add_patch(circle)\n","        ax0.scatter(circles[0], circles[1], s=20, c='g', marker='o')\n","        \n","        # Image Preprocessing (Normalization)\n","        # With eyelashes removal\n","        iris_norm = normalization(img, pupil_circle, iris_circle)\n","        \n","        # Without eyelashes removal\n","        # iris_norm = normalization(img, pupil_circle, iris_circle)\n","        \n","        ax1.imshow(iris_norm, cmap='gray')\n","        ax1.set_title(f'Normalized Image', fontsize=20)\n","        \n","        # Feature Extraction\n","        romv_img, noise_img = lash_removal_daugman(iris_norm, thresh=50)\n","        template, mask_noise = encode_iris(romv_img, noise_img, minw_length=18, mult=1, sigma_f=0.5)\n","        \n","        templates.append(template)\n","        masks.append(mask_noise)\n","        \n","        ax2.imshow(template, cmap='gray')\n","        ax2.set_title(f'Binary Encoded Image', fontsize=20)\n","        \n","        # Matching\n","        if len(templates) >= 2:\n","            hd_raw = HammingDistance(templates[0], masks[0], templates[i], masks[i])\n","            result = 'Match' if hd_raw <= 0.49 else 'Not Match'\n","            ax0.set_title(f'Hamming Distance: {hd_raw} ➜ {result}', fontsize=20)\n","        \n","    # print(f'Hamming Distance: {hd_raw}')\n","    # print(f'Matching Result: {hd_raw >= 0.5}')\n","        \n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"EP--hpOlxY08"},"source":["### <span style=\"color:#AF7AC5\">Accuracy Plot</span>"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":319,"status":"ok","timestamp":1679880267313,"user":{"displayName":"Oranus Kotsuwan","userId":"01427927832110327372"},"user_tz":-420},"id":"8z-aXEGCxY08"},"outputs":[],"source":["def acc_plot(img_num=1, compare_num=20, ref_img='Iris-Dataset/CASIA-IrisV2/device1/0000/0000_000.bmp'):\n","    templates = []\n","    masks = []\n","    df = pd.DataFrame(columns=[], index=[f\"Image {i}\" for i in range(compare_num)])\n","    \n","    # Read image\n","    ref_img = read_image(ref_img)\n","    \n","    # Image Preprocessing (Localization)\n","    init, snake, circles = localization(ref_img)\n","    \n","    pupil_circle = circles\n","    iris_circle = np.flip(np.array(snake).astype(int), 1)\n","    \n","    if circles[2] is None:\n","        print(f\"No circles found in image {img_num}\")\n","        return\n","    \n","    # Image Preprocessing (Normalization)\n","    iris_norm = normalization(ref_img, pupil_circle, iris_circle)\n","    \n","    # Feature Extraction\n","    romv_img, noise_img = lash_removal_daugman(iris_norm, thresh=50)\n","    template, mask_noise = encode_iris(romv_img, noise_img, minw_length=18, mult=1, sigma_f=0.5)\n","    \n","    templates.append(template)\n","    masks.append(mask_noise)\n","\n","    for i in range(img_num):\n","        hd_raw = []\n","        for j in range(compare_num):\n","            # Read image\n","            img = read_image(f'Iris-Dataset/CASIA-IrisV2/device1/00{str(i).zfill(2)}/00{str(i).zfill(2)}_0{str(j).zfill(2)}.bmp')\n","            \n","            # Image Preprocessing (Localization)\n","            init, snake, circles = localization(img)\n","            \n","            pupil_circle = circles\n","            iris_circle = np.flip(np.array(snake).astype(int), 1)\n","            \n","            if circles[2] is None:\n","                print(f\"No circles found in image {img_num}\")\n","                continue\n","            \n","            # Image Preprocessing (Normalization)\n","            iris_norm = normalization(img, pupil_circle, iris_circle)\n","            \n","            # Feature Extraction\n","            romv_img, noise_img = lash_removal_daugman(iris_norm, thresh=50)\n","            template, mask_noise = encode_iris(romv_img, noise_img, minw_length=18, mult=1, sigma_f=0.5)\n","            \n","            templates.append(template)\n","            masks.append(mask_noise)\n","            \n","            # Matching\n","            hd_raw.append(HammingDistance(templates[0], masks[0], templates[i*20+j+1], masks[i*20+j+1]))\n","\n","        df[f'Folder {i}'] = hd_raw\n","        \n","    return df"]},{"cell_type":"markdown","metadata":{"id":"tmWFCAt4xY08"},"source":["### <span style=\"color:#AF7AC5\">Accuracy Calculation</span>"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def write_iris_data_to_csv(col, rows, archive,test_fol=100,test_img=10):\n","  with open(archive, 'w') as csvfile:\n","        writer = csv.writer(csvfile)\n","        writer.writerow(col)\n","        writer.writerows(rows)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def calc_classification_metrics(truth, prediction):\n","\n","  if prediction == 1:\n","    if truth == 1:\n","      return \"TP\"\n","    else:\n","      return \"FP\"\n","  elif truth == 1:\n","    return \"FN\"\n","  else:\n","    return \"TN\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_img = 10 \n","rows = [['Image' + str(i)] for i in range(test_img)]\n","print(rows)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def acc_calc_demo(ref_imgs=0, ref_img=0, test_fol=100, test_img=10):  \n","    col = ['FolderName'] + ['folder' + str(i) + 'L' if j % 2 == 0 else 'folder' + str(i) + 'R' for i in range(test_fol) for j in range(2) ]\n","    rows = [['Image' + str(i)] for i in range(test_img)]\n","    \n","    img_1_L = read_image(\n","        f'Iris-Dataset/CASIA-Iris-Thousand/{str(ref_imgs).zfill(3)}/L/S5{str(ref_imgs).zfill(3)}L{str(ref_img).zfill(2)}.jpg')\n","\n","    img_1_R = read_image(\n","        f'Iris-Dataset/CASIA-Iris-Thousand/{str(ref_imgs).zfill(3)}/R/S5{str(ref_imgs).zfill(3)}R{str(ref_img).zfill(2)}.jpg')\n","\n","    error = 0\n","    \n","    folders = tqdm(range(test_fol), unit='folder', position=0, dynamic_ncols=True,)\n","    images = tqdm(range(test_img), unit='image', position=1, leave=False, dynamic_ncols=True)\n","    \n","    for folder in range(test_fol):\n","        folders.set_description(f\"Processing Folder {folder}\")\n","        folders.update()\n","        \n","        for num_img in range(test_img):\n","            images.set_description(f\"Processing Image {num_img}\")\n","            images.update()\n","            \n","            if folder == ref_imgs and num_img == ref_img:\n","                continue\n","            img_2_L = read_image(\n","                f'Iris-Dataset/CASIA-Iris-Thousand/{str(folder).zfill(3)}/L/S5{str(folder).zfill(3)}L{str(num_img).zfill(2)}.jpg')\n","\n","            img_2_R = read_image(\n","                f'Iris-Dataset/CASIA-Iris-Thousand/{str(folder).zfill(3)}/R/S5{str(folder).zfill(3)}R{str(num_img).zfill(2)}.jpg')\n","\n","            imgs = [[img_1_L, img_1_R], [img_2_L, img_2_R]]\n","            templates = [[], []]\n","            masks = [[], []]\n","            results = []\n","\n","            for i in range(len(imgs)):\n","                for j in range(len(imgs[i])):\n","                    img = imgs[i][j]\n","\n","                    _, snake, circles = localization(img, N=400)\n","\n","                    pupil_circle = circles\n","                    iris_circle = np.flip(np.array(snake).astype(int), 1)\n","\n","                    if circles[2] is None:\n","                        error += 1\n","                        break\n","\n","                    # Image Preprocessing (Normalization)\n","                    iris_norm = normalization(img, pupil_circle, iris_circle)\n","\n","                    # Feature Extraction\n","                    romv_img, noise_img = lash_removal_daugman(\n","                        iris_norm, thresh=50)\n","                    template, mask_noise = encode_iris(\n","                        romv_img, noise_img, minw_length=18, mult=1, sigma_f=0.5)\n","                    \n","\n","\n","                    templates[i].append(template)\n","                    masks[i].append(mask_noise)\n","\n","                    # Matching\n","                    if len(templates[1]) > 0:\n","                        hd_raw = HammingDistance(\n","                            templates[i-1][j], masks[i-1][j], templates[i][j], masks[i][j])\n","                        results.append(hd_raw)\n","\n","            if len(results) == 2:\n","                for value in results:\n","                    rows[num_img].append(value)\n","                \n","                if results[0] <= 0.48 and results[1] <= 0.48:\n","                    if folder == ref_imgs:\n","                        continue\n","                    else:\n","                        error += 1\n","                elif (results[0] <= 0.49 and results[1] <= 0.45) or (results[1] <= 0.49 and results[0] <= 0.45):\n","                    if folder == ref_imgs:\n","                        continue\n","                    else:\n","                        error += 1\n","                else:\n","                    continue\n","            else:\n","                error += 1\n","                print(f'Folder {folder} Image {num_img}: {results}')\n","                for j in range(1):\n","                    rows[num_img].append(np.nan)\n","    \n","        images.reset()\n","\n","    write_iris_data_to_csv(col, rows,'output2.csv', test_fol, test_img)\n","        \n","           \n","    return error/(test_fol * test_img-1)*100\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def acc_calc_demo2(ref_imgs=0, ref_img=0, test_fol=100, test_img=10, filename = 'test.csv'):    \n","\n","    col = ['FolderName'] + ['folder' + str(i) for i in range (0,1000)  ]\n","    rows = [['Image' + str(i)] for i in range(test_img)]\n","    data1 = []\n","    \n","    img_1 = read_image(\n","        f'archive/{str(ref_imgs).zfill(3)}/S6{str(ref_imgs).zfill(3)}S{str(ref_img).zfill(2)}.jpg')\n","    \n","\n","\n","    error = 0\n","    \n","    folders = tqdm(range(test_fol), unit='folder', position=0, dynamic_ncols=True,)\n","    images = tqdm(range(test_img), unit='image', position=1, leave=False, dynamic_ncols=True)\n","    \n","    for folder in range(test_fol):\n","        folders.set_description(f\"Processing Folder {folder}\")\n","        folders.update()\n","        \n","        for num_img in range(test_img):\n","            images.set_description(f\"Processing Image {num_img}\")\n","            images.update()\n","            \n","            if folder == ref_imgs and num_img == ref_img :\n","                continue\n","            \n","\n","            img_2 = read_image(\n","                 f'archive/{str(folder).zfill(3)}/S6{str(folder).zfill(3)}S{str(num_img).zfill(2)}.jpg')\n","\n","            imgs = [[img_1], [img_2]]\n","            templates = [[], []]\n","            masks = [[], []]\n","            results = []\n","            \n","\n","            for i in range(len(imgs)):\n","                for j in range(len(imgs[i])):\n","                    img = imgs[i][j]\n","\n","                    _, snake, circles = localization(img, N=400)\n","\n","                    pupil_circle = circles\n","                    iris_circle = np.flip(np.array(snake).astype(int), 1)\n","\n","                    if circles[2] is None:\n","                        error += 1\n","                        break\n","\n","                    # Image Preprocessing (Normalization)\n","                    iris_norm = normalization(img, pupil_circle, iris_circle)\n","\n","                    # Feature Extraction\n","                    romv_img, noise_img = lash_removal_daugman(\n","                        iris_norm, thresh=50)\n","                    template, mask_noise = encode_iris(\n","                        romv_img, noise_img, minw_length=18, mult=1, sigma_f=0.5)\n","\n","                    templates[i].append(template)\n","                    masks[i].append(mask_noise)\n","\n","                    # Matching\n","                    if len(templates[1]) > 0:\n","                        hd_raw = HammingDistance(\n","                            templates[i-1][j], masks[i-1][j], templates[i][j], masks[i][j])\n","                        results.append(hd_raw)\n","\n","            if len(results) == 2:\n","                data1.append(results)\n","                if results == []:\n","                    continue\n","                if results[0] <= 0.48 :\n","                    continue\n","                \n","                else:\n","                    error += 1\n","                    \n","            else:\n","                error += 1\n","                print(f'Folder {folder} Image {num_img}: {results}')\n","        \n","        images.reset()\n","\n","        \n","        return error/(test_fol * test_img - 1)*100"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def acc_calc_demo3(ref_imgs=0, ref_img=0, test_fol=60, test_img=20):  \n","    col = ['FolderName'] + ['folder' + str(i) for i in range(test_fol) ]\n","    rows = [['Image' + str(i)] for i in range(test_img)]\n","    \n","\n","    img_1 = read_image(\n","        f'Iris-Dataset/CASIA-IrisV2/device1/{str(ref_imgs).zfill(4)}/0{str(ref_imgs).zfill(3)}_{str(ref_img).zfill(3)}.bmp')\n","    \n","\n","\n","    error = 0\n","    \n","    folders = tqdm(range(test_fol), unit='folder', position=0, dynamic_ncols=True,)\n","    images = tqdm(range(test_img), unit='image', position=1, leave=False, dynamic_ncols=True)\n","    \n","\n","    for folder in range(test_fol):\n","        folders.set_description(f\"Processing Folder {folder}\")\n","        folders.update()\n","        \n","        for num_img in range(test_img):\n","            images.set_description(f\"Processing Image {num_img}\")\n","            images.update()\n","            \n","            if folder == ref_imgs and num_img == ref_img :\n","                continue\n","            \n","\n","            img_2 = read_image(\n","                 f'Iris-Dataset/CASIA-IrisV2/device1/{str(folder).zfill(4)}/0{str(folder).zfill(3)}_{str(num_img).zfill(3)}.bmp')\n","\n","            imgs = [[img_1], [img_2]]\n","            templates = [[], []]\n","            masks = [[], []]\n","            results = []\n","            \n","\n","            for i in range(len(imgs)):\n","                for j in range(len(imgs[i])):\n","                    img = imgs[i][j]\n","\n","                    _, snake, circles = localization(img, N=400)\n","\n","                    pupil_circle = circles\n","                    iris_circle = np.flip(np.array(snake).astype(int), 1)\n","\n","                    if circles[2] is None:\n","                        error += 1\n","                        break\n","\n","                    # Image Preprocessing (Normalization)\n","                    iris_norm = normalization(img, pupil_circle, iris_circle)\n","\n","                    # Feature Extraction\n","                    romv_img, noise_img = lash_removal_daugman(\n","                        iris_norm, thresh=50)\n","                    template, mask_noise = encode_iris(\n","                        romv_img, noise_img, minw_length=18, mult=1, sigma_f=0.5)\n","\n","                    templates[i].append(template)\n","                    masks[i].append(mask_noise)\n","\n","                    # Matching\n","                    if len(templates[1]) > 0:\n","                        hd_raw = HammingDistance(\n","                            templates[i-1][j], masks[i-1][j], templates[i][j], masks[i][j])\n","                        results.append(hd_raw)\n","\n","            if len(results) == 1:\n","                for value in results:\n","                    rows[num_img].append(value)\n","                if results == []:\n","                    continue\n","                if results[0] <= 0.48 :\n","                    continue\n","                \n","                else:\n","                    error += 1\n","                    \n","            else:\n","                error += 1\n","                print(f'Folder {folder} Image {num_img}: {results}')\n","                rows[num_img].append(np.nan)\n","        \n","        images.reset()\n","        \n","    write_iris_data_to_csv(col, rows,'output3.csv', test_fol, test_img)\n","    \n","        \n","           \n","    return error/(test_fol * test_img-1)*100\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def acc_calc_demo35(ref_imgs=0, ref_img=0, test_fol=60, test_img=20):  \n","    col = ['FolderName'] + ['folder' + str(i) for i in range(test_fol) ]\n","    rows = [['Image' + str(i)] for i in range(test_img)]\n","    \n","    error = 0\n","    \n","    folders = tqdm(range(test_fol), unit='folder', position=0, dynamic_ncols=True,)\n","    images = tqdm(range(test_img), unit='image', position=1, leave=False, dynamic_ncols=True)\n","    for ref_imgs in range(ref_imgs):\n","        for ref_img in range(ref_img):\n","            img_1 = read_image(\n","            f'Iris-Dataset/CASIA-IrisV2/device1/{str(ref_imgs).zfill(4)}/0{str(ref_imgs).zfill(3)}_{str(ref_img).zfill(3)}.bmp')\n","\n","            for folder in range(test_fol):\n","                folders.set_description(f\"Processing Folder {folder}\")\n","                folders.update()\n","                \n","                for num_img in range(test_img):\n","                    images.set_description(f\"Processing Image {num_img}\")\n","                    images.update()  \n","\n","                    \n","                    \n","                    if folder == ref_imgs and num_img == ref_img :\n","                        continue\n","                    \n","\n","                    img_2 = read_image(\n","                        f'Iris-Dataset/CASIA-IrisV2/device1/{str(folder).zfill(4)}/0{str(folder).zfill(3)}_{str(num_img).zfill(3)}.bmp')\n","\n","                    imgs = [[img_1], [img_2]]\n","                    templates = [[], []]\n","                    masks = [[], []]\n","                    results = []\n","                    \n","\n","                    for i in range(len(imgs)):\n","                        for j in range(len(imgs[i])):\n","                            img = imgs[i][j]\n","\n","                            _, snake, circles = localization(img, N=400)\n","\n","                            pupil_circle = circles\n","                            iris_circle = np.flip(np.array(snake).astype(int), 1)\n","\n","                            if circles[2] is None:\n","                                error += 1\n","                                break\n","\n","                            # Image Preprocessing (Normalization)\n","                            iris_norm = normalization(img, pupil_circle, iris_circle)\n","\n","                            # Feature Extraction\n","                            romv_img, noise_img = lash_removal_daugman(\n","                                iris_norm, thresh=50)\n","                            template, mask_noise = encode_iris(\n","                                romv_img, noise_img, minw_length=18, mult=1, sigma_f=0.5)\n","\n","                            templates[i].append(template)\n","                            masks[i].append(mask_noise)\n","\n","                            # Matching\n","                            if len(templates[1]) > 0:\n","                                hd_raw = HammingDistance(\n","                                    templates[i-1][j], masks[i-1][j], templates[i][j], masks[i][j])\n","                                results.append(hd_raw)\n","\n","                    if len(results) == 1:\n","                        for value in results:\n","                            rows[num_img].append(value)\n","                        if results == []:\n","                            continue\n","                        if results[0] <= 0.48 :\n","                            continue\n","                        \n","                        else:\n","                            error += 1\n","                            \n","                    else:\n","                        error += 1\n","                        print(f'Folder {folder} Image {num_img}: {results}')\n","                        rows[num_img].append(np.nan)\n","                \n","                images.reset()\n","                \n","            write_iris_data_to_csv(col, rows,'output2.csv', test_fol, test_img)\n","        \n","        \n","           \n","    return error/(test_fol * test_img-1)*100"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def acc_calc_demo36(ref_imgs=0, ref_img=0, test_fol=60, test_img=20):  \n","    col = ['FolderName'] + ['folder' + str(i) for i in range(test_fol) ]\n","    rows = [['Image' + str(i)] for i in range(test_img)]\n","    classification_results = [] \n","    \n","\n","    img_1 = read_image(\n","        f'Iris-Dataset/CASIA-IrisV2/device1/{str(ref_imgs).zfill(4)}/0{str(ref_imgs).zfill(3)}_{str(ref_img).zfill(3)}.bmp')\n","    \n","\n","\n","    error = 0\n","    \n","    folders = tqdm(range(test_fol), unit='folder', position=0, dynamic_ncols=True,)\n","    images = tqdm(range(test_img), unit='image', position=1, leave=False, dynamic_ncols=True)\n","    for ref_imgs in range(test_fol):\n","        for ref_img in range(test_img):\n","            for folder in range(test_fol):\n","                for num_img in range(test_img):\n","                    img_1 = read_image(\n","                    f'Iris-Dataset/CASIA-IrisV2/device1/{str(ref_imgs).zfill(4)}/0{str(ref_imgs).zfill(3)}_{str(ref_img).zfill(3)}.bmp')\n","\n","                    for folder in range(test_fol):\n","                        folders.set_description(f\"Processing Folder {folder}\")\n","                        folders.update()\n","                        \n","                        for num_img in range(test_img):\n","                            images.set_description(f\"Processing Image {num_img}\")\n","                            images.update()\n","                            \n","                            \n","                            \n","\n","                            img_2 = read_image(\n","                                f'Iris-Dataset/CASIA-IrisV2/device1/{str(folder).zfill(4)}/0{str(folder).zfill(3)}_{str(num_img).zfill(3)}.bmp')\n","\n","                            imgs = [[img_1], [img_2]]\n","                            templates = [[], []]\n","                            masks = [[], []]\n","                            results = []\n","                            \n","\n","                            for i in range(len(imgs)):\n","                                for j in range(len(imgs[i])):\n","                                    img = imgs[i][j]\n","\n","                                    _, snake, circles = localization(img, N=400)\n","\n","                                    pupil_circle = circles\n","                                    iris_circle = np.flip(np.array(snake).astype(int), 1)\n","\n","                                    if circles[2] is None:\n","                                        error += 1\n","                                        break\n","\n","                                    # Image Preprocessing (Normalization)\n","                                    iris_norm = normalization(img, pupil_circle, iris_circle)\n","\n","                                    # Feature Extraction\n","                                    romv_img, noise_img = lash_removal_daugman(\n","                                        iris_norm, thresh=50)\n","                                    template, mask_noise = encode_iris(\n","                                        romv_img, noise_img, minw_length=18, mult=1, sigma_f=0.5)\n","\n","                                    templates[i].append(template)\n","                                    masks[i].append(mask_noise)\n","\n","                                    # Matching\n","                                    if len(templates[1]) > 0:\n","                                        hd_raw = HammingDistance(\n","                                            templates[i-1][j], masks[i-1][j], templates[i][j], masks[i][j])\n","                                        results.append(hd_raw)\n","\n","                            if len(results) == 1:\n","                                for value in results:\n","                                    rows[num_img].append(value)\n","                                if results == []:\n","                                    continue\n","                                if results[0] <= 0.48 :\n","                                    continue\n","                                \n","                                else:\n","                                    error += 1\n","                                    \n","                            else:\n","                                error += 1\n","                                print(f'Folder {folder} Image {num_img}: {results}')\n","                                rows[num_img].append(np.nan)\n","                        \n","                        images.reset()\n","                        \n","                            \n","                for num_img in range(test_img):\n","                    classification_results.append([])\n","                    for value in results:\n","                        if value <= 0.48:  \n","                            classification = calc_classification_metrics(1, 1)  \n","                        else:\n","                            classification = calc_classification_metrics(1, 0)  \n","                        classification_results[num_img].append(classification)\n","\n","                \n","                for i in range(test_img):\n","                    rows[i].extend(classification_results[i])    \n","                    write_iris_data_to_csv(col, rows,'output2.csv', test_fol, test_img)\n","            \n","        \n","           \n","    return error/(test_fol * test_img-1)*100"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def acc_calc_demo37(ref_imgs=0, ref_img=0, test_fol=60, test_img=20):  \n","    col = ['FolderName'] + ['folder' + str(i) for i in range(test_fol) ]\n","    rows = [['Image' + str(i)] for i in range(test_img)]\n","    tp_count = 0\n","    tn_count = 0\n","    fp_count = 0\n","    fn_count = 0\n","    \n","\n","    img_1 = read_image(\n","        f'Iris-Dataset/CASIA-IrisV2/device1/{str(ref_imgs).zfill(4)}/0{str(ref_imgs).zfill(3)}_{str(ref_img).zfill(3)}.bmp')\n","    \n","\n","\n","    error = 0\n","    \n","    folders = tqdm(range(test_fol), unit='folder', position=0, dynamic_ncols=True,)\n","    images = tqdm(range(test_img), unit='image', position=1, leave=False, dynamic_ncols=True)\n","    \n","\n","    for folder in range(test_fol):\n","        folders.set_description(f\"Processing Folder {folder}\")\n","        folders.update()\n","        \n","        for num_img in range(test_img):\n","            images.set_description(f\"Processing Image {num_img}\")\n","            images.update()\n","            for ref_imgs in range(test_fol):\n","              for ref_img in range(test_img):\n","                  if folder != ref_imgs or num_img != ref_img:\n","                      img_2 = read_image(\n","                          f'Iris-Dataset/CASIA-IrisV2/device1/{str(ref_imgs).zfill(4)}/0{str(ref_imgs).zfill(3)}_{str(ref_img).zfill(3)}.bmp')\n","            if folder == ref_imgs and num_img == ref_img :\n","                continue\n","            \n","\n","            img_2 = read_image(\n","                 f'Iris-Dataset/CASIA-IrisV2/device1/{str(folder).zfill(4)}/0{str(folder).zfill(3)}_{str(num_img).zfill(3)}.bmp')\n","\n","            imgs = [[img_1], [img_2]]\n","            templates = [[], []]\n","            masks = [[], []]\n","            results = []\n","            \n","\n","            for i in range(len(imgs)):\n","                for j in range(len(imgs[i])):\n","                    img = imgs[i][j]\n","\n","                    _, snake, circles = localization(img, N=400)\n","\n","                    pupil_circle = circles\n","                    iris_circle = np.flip(np.array(snake).astype(int), 1)\n","\n","                    if circles[2] is None:\n","                        error += 1\n","                        break\n","\n","                    # Image Preprocessing (Normalization)\n","                    iris_norm = normalization(img, pupil_circle, iris_circle)\n","\n","                    # Feature Extraction\n","                    romv_img, noise_img = lash_removal_daugman(\n","                        iris_norm, thresh=50)\n","                    template, mask_noise = encode_iris(\n","                        romv_img, noise_img, minw_length=18, mult=1, sigma_f=0.5)\n","\n","                    templates[i].append(template)\n","                    masks[i].append(mask_noise)\n","\n","                    # Matching\n","                    if len(templates[1]) > 0:\n","                        hd_raw = HammingDistance(\n","                            templates[i-1][j], masks[i-1][j], templates[i][j], masks[i][j])\n","                        results.append(hd_raw)\n","\n","            if len(results) == 1:\n","                for value in results:\n","                    rows[num_img].append(value)\n","                if results == []:\n","                    continue\n","                if results[0] <= 0.48 :\n","                    continue\n","                \n","                else:\n","                    error += 1\n","                    \n","            else:\n","                error += 1\n","                print(f'Folder {folder} Image {num_img}: {results}')\n","                rows[num_img].append(np.nan)\n","        for num_img in range(test_img):\n","            for value in results:\n","                if value <= 0.48:\n","                    classification = calc_classification_metrics(1, 1)\n","                    if classification == \"TP\":\n","                        tp_count += 1\n","                    elif classification == \"TN\":\n","                        tn_count += 1  # Assuming all non-reference are negative\n","                else:\n","                    classification = calc_classification_metrics(1, 0)\n","                    if classification == \"FN\":\n","                        fn_count += 1\n","                    elif classification == \"FP\":\n","                        fp_count += 1\n","            print(\"TP:\", tp_count)\n","            print(\"TN:\", tn_count)\n","            print(\"FP:\", fp_count)\n","            print(\"FN:\", fn_count)\n","            images.reset()\n","        \n","    write_iris_data_to_csv(col, rows,'output2.csv', test_fol, test_img)\n","    \n","        \n","           \n","    return error/(test_fol * test_img-1)*100"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def acc_calc_demo38(ref_imgs=0, ref_img=0, test_fol=60, test_img=20):  \n","    col = ['FolderName'] + ['folder' + str(i) for i in range(test_fol) ]\n","    rows = [['Image' + str(i)] for i in range(test_img)]\n","    tp_count = 0\n","    tn_count = 0\n","    fp_count = 0\n","    fn_count = 0\n","    \n","\n","    img_1 = read_image(\n","        f'Iris-Dataset/CASIA-IrisV2/device1/{str(ref_imgs).zfill(4)}/0{str(ref_imgs).zfill(3)}_{str(ref_img).zfill(3)}.bmp')\n","    \n","\n","\n","    error = 0\n","    \n","    folders = tqdm(range(test_fol), unit='folder', position=0, dynamic_ncols=True,)\n","    images = tqdm(range(test_img), unit='image', position=1, leave=False, dynamic_ncols=True)\n","    thresholds = np.arange(0.0, 1.01, 0.01)\n","    false_positive_rates = []\n","    false_negative_rates = []\n","\n","    for folder in range(test_fol):\n","        folders.set_description(f\"Processing Folder {folder}\")\n","        folders.update()\n","        \n","        for num_img in range(test_img):\n","            images.set_description(f\"Processing Image {num_img}\")\n","            images.update()\n","            for ref_imgs in range(test_fol):\n","              for ref_img in range(test_img):\n","                  if folder != ref_imgs or num_img != ref_img:\n","                      img_2 = read_image(\n","                          f'Iris-Dataset/CASIA-IrisV2/device1/{str(ref_imgs).zfill(4)}/0{str(ref_imgs).zfill(3)}_{str(ref_img).zfill(3)}.bmp')\n","            if folder == ref_imgs and num_img == ref_img :\n","                continue\n","            \n","\n","            img_2 = read_image(\n","                 f'Iris-Dataset/CASIA-IrisV2/device1/{str(folder).zfill(4)}/0{str(folder).zfill(3)}_{str(num_img).zfill(3)}.bmp')\n","\n","            imgs = [[img_1], [img_2]]\n","            templates = [[], []]\n","            masks = [[], []]\n","            results = []\n","            \n","\n","            for i in range(len(imgs)):\n","                for j in range(len(imgs[i])):\n","                    img = imgs[i][j]\n","\n","                    _, snake, circles = localization(img, N=400)\n","\n","                    pupil_circle = circles\n","                    iris_circle = np.flip(np.array(snake).astype(int), 1)\n","\n","                    if circles[2] is None:\n","                        error += 1\n","                        break\n","\n","                    # Image Preprocessing (Normalization)\n","                    iris_norm = normalization(img, pupil_circle, iris_circle)\n","\n","                    # Feature Extraction\n","                    romv_img, noise_img = lash_removal_daugman(\n","                        iris_norm, thresh=50)\n","                    template, mask_noise = encode_iris(\n","                        romv_img, noise_img, minw_length=18, mult=1, sigma_f=0.5)\n","\n","                    templates[i].append(template)\n","                    masks[i].append(mask_noise)\n","\n","                    # Matching\n","                    if len(templates[1]) > 0:\n","                        hd_raw = HammingDistance(\n","                            templates[i-1][j], masks[i-1][j], templates[i][j], masks[i][j])\n","                        results.append(hd_raw)\n","\n","            if len(results) == 1:\n","                for value in results:\n","                    rows[num_img].append(value)\n","                if results == []:\n","                    continue\n","                if results[0] <= 0.48 :\n","                    continue\n","                \n","                else:\n","                    error += 1\n","                    \n","            else:\n","                error += 1\n","                print(f'Folder {folder} Image {num_img}: {results}')\n","                rows[num_img].append(np.nan)\n","        for num_img in range(test_img):\n","            for value in results:\n","                if value <= 0.48:\n","                    classification = calc_classification_metrics(1, 1)\n","                    if classification == \"TP\":\n","                        tp_count += 1\n","                    elif classification == \"TN\":\n","                        tn_count += 1  # Assuming all non-reference are negative\n","                else:\n","                    classification = calc_classification_metrics(1, 0)\n","                    if classification == \"FN\":\n","                        fn_count += 1\n","                    elif classification == \"FP\":\n","                        fp_count += 1\n","        print(\"TP:\", tp_count)\n","        print(\"TN:\", tn_count)\n","        print(\"FP:\", fp_count)\n","        print(\"FN:\", fn_count)\n","                        \n","\n","                        \n","        plt.figure()\n","        plt.plot(fp_count, fn_count, label='ROC Curve')\n","        plt.xlabel('False Positive ')\n","        plt.ylabel('False Negative ')\n","        plt.title('ROC Curve for Iris Recognition')\n","        plt.grid(True)\n","        plt.show()\n","        images.reset()\n","        \n","    write_iris_data_to_csv(col, rows,'output2.csv', test_fol, test_img)\n","    \n","        \n","           \n","    return error/(test_fol * test_img-1)*100"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","def acc_calc_demo39(ref_imgs=0, ref_img=0, test_fol=5, test_img=2): \n","    \n","    col = ['FolderName'] + ['folder' + str(i) for i in range(test_fol) ]\n","    rows = [['Image' + str(i)] for i in range(test_img)]\n","    tp_count = 0\n","    tn_count = 0\n","    fp_count = 0\n","    fn_count = 0\n","    fn_list = []\n","    fp_list = []\n","    \n","\n","    img_1 = read_image(\n","        f'Iris-Dataset/CASIA-IrisV2/device1/{str(ref_imgs).zfill(4)}/0{str(ref_imgs).zfill(3)}_{str(ref_img).zfill(3)}.bmp')\n","    \n","\n","\n","    error = 0\n","    \n","    folders = tqdm(range(test_fol), unit='folder', position=0, dynamic_ncols=True,)\n","    images = tqdm(range(test_img), unit='image', position=1, leave=False, dynamic_ncols=True)\n","    \n","    \n","\n","    for folder in range(test_fol):\n","        folders.set_description(f\"Processing Folder {folder}\")\n","        folders.update()\n","        \n","        for num_img in range(test_img):\n","            images.set_description(f\"Processing Image {num_img}\")\n","            images.update()\n","            for ref_imgs in range(test_fol):\n","              for ref_img in range(test_img):\n","                  if folder != ref_imgs or num_img != ref_img:\n","                      img_2 = read_image(\n","                          f'Iris-Dataset/CASIA-IrisV2/device1/{str(ref_imgs).zfill(4)}/0{str(ref_imgs).zfill(3)}_{str(ref_img).zfill(3)}.bmp')\n","            if folder == ref_imgs and num_img == ref_img :\n","                continue\n","            \n","\n","            img_2 = read_image(\n","                 f'Iris-Dataset/CASIA-IrisV2/device1/{str(folder).zfill(4)}/0{str(folder).zfill(3)}_{str(num_img).zfill(3)}.bmp')\n","\n","            imgs = [[img_1], [img_2]]\n","            templates = [[], []]\n","            \n","            masks = [[], []]\n","            results = []\n","            \n","\n","            for i in range(len(imgs)):\n","                for j in range(len(imgs[i])):\n","                    img = imgs[i][j]\n","\n","                    _, snake, circles = localization(img, N=400)\n","\n","                    pupil_circle = circles\n","                    iris_circle = np.flip(np.array(snake).astype(int), 1)\n","\n","                    if circles[2] is None:\n","                        error += 1\n","                        break\n","\n","                    # Image Preprocessing (Normalization)\n","                    iris_norm = normalization(img, pupil_circle, iris_circle)\n","\n","                    # Feature Extraction\n","                    romv_img, noise_img = lash_removal_daugman(\n","                        iris_norm, thresh=50)\n","                    template, mask_noise = encode_iris(\n","                        romv_img, noise_img, minw_length=18, mult=1, sigma_f=0.5)\n","\n","                    templates[i].append(template)\n","                    masks[i].append(mask_noise)\n","\n","                    # Matching\n","                    if len(templates[1]) > 0:\n","                        hd_raw = HammingDistance(\n","                            templates[i-1][j], masks[i-1][j], templates[i][j], masks[i][j])\n","                        results.append(hd_raw)\n","\n","            if len(results) == 1:\n","                for value in results:\n","                    rows[num_img].append(value)\n","                if results == []:\n","                    continue\n","                if results[0] <= 0 :\n","                    continue\n","                \n","                else:\n","                    error += 1\n","                    \n","            else:\n","                error += 1\n","                print(f'Folder {folder} Image {num_img}: {results}')\n","                rows[num_img].append(np.nan)\n","        for num_img in range(test_img):\n","            for value in results:\n","                if value <= 0.4725:\n","                    classification = calc_classification_metrics(1, 1)\n","                    if classification == \"TP\":\n","                        tp_count += 1\n","                    elif classification == \"TN\":\n","                        tn_count += 1  \n","                else:\n","                    classification = calc_classification_metrics(1, 0)\n","                    if classification == \"FN\":\n","                        fn_count += 1\n","                        fn_list.append(fn_count)\n","                    elif classification == \"FP\":\n","                        fp_count += 1\n","                        fp_list.append(fp_count)\n","            print(\"TP:\", tp_count)\n","            print(\"TN:\", tn_count)\n","            print(\"FP:\", fp_count)\n","            print(\"FN:\", fn_count)\n","            images.reset()\n","        \n","    write_iris_data_to_csv(col, rows,'output3.csv', test_fol, test_img)\n","    plt.plot(range(len(fn_list)), fn_list, label='False Negatives')\n","    plt.plot(range(len(fp_list)), fp_list, label='False Positives')\n","    plt.xlabel('Iterations')\n","    plt.ylabel('Count')\n","    plt.title('FN vs FP')\n","    plt.legend()\n","    plt.show()\n","        \n","           \n","    return error/(test_fol * test_img-1)*100\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def acc_calc_demo5(ref_imgs=0, ref_img=0, test_fol=100, test_img=10):  \n","    col = ['FolderName'] + ['folder' + str(i) + 'L' if j % 2 == 0 else 'folder' + str(i) + 'R' for i in range(test_fol) for j in range(2) ]\n","    rows = [['Image' + str(i)] for i in range(test_img)]\n","    \n","    img_1_L = read_image(\n","         f'CASIA-Iris-Interval/{str(ref_imgs).zfill(3)}/L/S1{str(ref_imgs).zfill(3)}L{str(ref_img).zfill(2)}.jpg')\n","        \n","    img_1_R = read_image(\n","         f'CASIA-Iris-Interval/{str(ref_imgs).zfill(3)}/R/S1{str(ref_imgs).zfill(3)}R{str(ref_img).zfill(2)}.jpg')\n","    \n","        \n","\n","    error = 0\n","    \n","    folders = tqdm(range(test_fol), unit='folder', position=0, dynamic_ncols=True,)\n","    images = tqdm(range(test_img), unit='image', position=1, leave=False, dynamic_ncols=True)\n","    \n","    for folder in range(test_fol):\n","        folders.set_description(f\"Processing Folder {folder}\")\n","        folders.update()\n","        \n","        for num_img in range(test_img):\n","            images.set_description(f\"Processing Image {num_img}\")\n","            images.update()\n","            \n","            if folder == ref_imgs and num_img == ref_img:\n","                continue\n","            img_2_L = read_image(\n","            f'CASIA-Iris-Interval/{str(folder).zfill(3)}/L/S1{str(folder).zfill(3)}L{str(num_img).zfill(2)}.jpg')\n","            img_2_R = read_image(\n","            f'CASIA-Iris-Interval/{str(folder).zfill(3)}/R/S1{str(folder).zfill(3)}R{str(num_img).zfill(2)}.jpg')\n","\n","            imgs = [[img_1_L, img_1_R], [img_2_L, img_2_R]]\n","            templates = [[], []]\n","            masks = [[], []]\n","            results = []\n","\n","            for i in range(len(imgs)):\n","                for j in range(len(imgs[i])):\n","                    img = imgs[i][j]\n","\n","                    _, snake, circles = localization(img, N=400)\n","\n","                    pupil_circle = circles\n","                    iris_circle = np.flip(np.array(snake).astype(int), 1)\n","\n","                    if circles[2] is None:\n","                        error += 1\n","                        break\n","\n","                    # Image Preprocessing (Normalization)\n","                    iris_norm = normalization(img, pupil_circle, iris_circle)\n","\n","                    # Feature Extraction\n","                    romv_img, noise_img = lash_removal_daugman(\n","                        iris_norm, thresh=50)\n","                    template, mask_noise = encode_iris(\n","                        romv_img, noise_img, minw_length=18, mult=1, sigma_f=0.5)\n","                    \n","\n","\n","                    templates[i].append(template)\n","                    masks[i].append(mask_noise)\n","\n","                    # Matching\n","                    if len(templates[1]) > 0:\n","                        hd_raw = HammingDistance(\n","                            templates[i-1][j], masks[i-1][j], templates[i][j], masks[i][j])\n","                        results.append(hd_raw)\n","\n","            if len(results) == 2:\n","                for value in results:\n","                    rows[num_img].append(value)\n","                \n","                if results[0] <= 0.48 and results[1] <= 0.48:\n","                    if folder == ref_imgs:\n","                        continue\n","                    else:\n","                        error += 1\n","                elif (results[0] <= 0.49 and results[1] <= 0.45) or (results[1] <= 0.49 and results[0] <= 0.45):\n","                    if folder == ref_imgs:\n","                        continue\n","                    else:\n","                        error += 1\n","                else:\n","                    continue\n","            else:\n","                error += 1\n","                print(f'Folder {folder} Image {num_img}: {results}')\n","                for j in range(1):\n","                    rows[num_img].append(np.nan)\n","    \n","        images.reset()\n","\n","    write_iris_data_to_csv(col, rows,'output3.csv', test_fol, test_img)\n","        \n","           \n","    return error/(test_fol * test_img-1)*100\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def acc_calc_demo01(ref_imgs=0, ref_img=0, test_fol=100, test_img=10):  \n","    col = ['FolderName'] + ['folder' + str(i) for i in range(test_fol) ]\n","    rows = [['Image' + str(i)] for i in range(test_img)]\n","    \n","    img_1 = read_image(\n","        f'archive/{str(ref_imgs).zfill(3)}/S6{str(ref_imgs).zfill(3)}S{str(ref_img).zfill(2)}.jpg')\n","    \n","\n","\n","    error = 0\n","    \n","    folders = tqdm(range(test_fol), unit='folder', position=0, dynamic_ncols=True,)\n","    images = tqdm(range(test_img), unit='image', position=1, leave=False, dynamic_ncols=True)\n","    \n","    for folder in range(test_fol):\n","        folders.set_description(f\"Processing Folder {folder}\")\n","        folders.update()\n","        \n","        for num_img in range(test_img):\n","            images.set_description(f\"Processing Image {num_img}\")\n","            images.update()\n","            \n","            if folder == ref_imgs and num_img == ref_img :\n","                continue\n","            \n","\n","            img_2 = read_image(\n","                 f'archive/{str(folder).zfill(3)}/S6{str(folder).zfill(3)}S{str(num_img).zfill(2)}.jpg')\n","\n","            imgs = [[img_1], [img_2]]\n","            templates = [[], []]\n","            masks = [[], []]\n","            results = []\n","            \n","\n","            for i in range(len(imgs)):\n","                for j in range(len(imgs[i])):\n","                    img = imgs[i][j]\n","\n","                    _, snake, circles = localization(img, N=400)\n","\n","                    pupil_circle = circles\n","                    iris_circle = np.flip(np.array(snake).astype(int), 1)\n","\n","                    if circles[2] is None:\n","                        error += 1\n","                        break\n","\n","                    # Image Preprocessing (Normalization)\n","                    iris_norm = normalization(img, pupil_circle, iris_circle)\n","\n","                    # Feature Extraction\n","                    romv_img, noise_img = lash_removal_daugman(\n","                        iris_norm, thresh=50)\n","                    template, mask_noise = encode_iris(\n","                        romv_img, noise_img, minw_length=18, mult=1, sigma_f=0.5)\n","\n","                    templates[i].append(template)\n","                    masks[i].append(mask_noise)\n","\n","                    # Matching\n","                    if len(templates[1]) > 0:\n","                        hd_raw = HammingDistance(\n","                            templates[i-1][j], masks[i-1][j], templates[i][j], masks[i][j])\n","                        results.append(hd_raw)\n","\n","            if len(results) == 1:\n","                for value in results:\n","                    rows[num_img].append(value)\n","                if results == []:\n","                    continue\n","                if results[0] <= 0.48 :\n","                    continue\n","                \n","                else:\n","                    error += 1\n","                    \n","            else:\n","                error += 1\n","                print(f'Folder {folder} Image {num_img}: {results}')\n","                rows[num_img].append(np.nan)\n","        \n","        images.reset()\n","    write_iris_data_to_csv(col, rows,'output3.csv', test_fol, test_img)\n","    \n","        \n","           \n","    return error/(test_fol * test_img-1)*100\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":447,"status":"ok","timestamp":1679880313501,"user":{"displayName":"Oranus Kotsuwan","userId":"01427927832110327372"},"user_tz":-420},"id":"VrtDkTRXxY08"},"outputs":[],"source":["def acc_calc(ref_imgs=0, ref_img=0, test_fol=100, test_img=10):    \n","    img_1_L = read_image(\n","        f'Iris-Dataset/CASIA-Iris-Thousand/{str(ref_imgs).zfill(3)}/L/S5{str(ref_imgs).zfill(3)}L{str(ref_img).zfill(2)}.jpg')\n","\n","    img_1_R = read_image(\n","        f'Iris-Dataset/CASIA-Iris-Thousand/{str(ref_imgs).zfill(3)}/R/S5{str(ref_imgs).zfill(3)}R{str(ref_img).zfill(2)}.jpg')\n","\n","    error = 0\n","    \n","    folders = tqdm(range(test_fol), unit='folder', position=0, dynamic_ncols=True,)\n","    images = tqdm(range(test_img), unit='image', position=1, leave=False, dynamic_ncols=True)\n","    \n","    for folder in range(test_fol):\n","        folders.set_description(f\"Processing Folder {folder}\")\n","        folders.update()\n","        \n","        for num_img in range(test_img):\n","            images.set_description(f\"Processing Image {num_img}\")\n","            images.update()\n","            \n","            if folder == ref_imgs and num_img == ref_img:\n","                continue\n","            img_2_L = read_image(\n","                f'Iris-Dataset/CASIA-Iris-Thousand/{str(folder).zfill(3)}/L/S5{str(folder).zfill(3)}L{str(num_img).zfill(2)}.jpg')\n","\n","            img_2_R = read_image(\n","                f'Iris-Dataset/CASIA-Iris-Thousand/{str(folder).zfill(3)}/R/S5{str(folder).zfill(3)}R{str(num_img).zfill(2)}.jpg')\n","\n","            imgs = [[img_1_L, img_1_R], [img_2_L, img_2_R]]\n","            templates = [[], []]\n","            masks = [[], []]\n","            results = []\n","\n","            for i in range(len(imgs)):\n","                for j in range(len(imgs[i])):\n","                    img = imgs[i][j]\n","\n","                    _, snake, circles = localization(img, N=400)\n","\n","                    pupil_circle = circles\n","                    iris_circle = np.flip(np.array(snake).astype(int), 1)\n","\n","                    if circles[2] is None:\n","                        error += 1\n","                        break\n","\n","                    # Image Preprocessing (Normalization)\n","                    iris_norm = normalization(img, pupil_circle, iris_circle)\n","\n","                    # Feature Extraction\n","                    romv_img, noise_img = lash_removal_daugman(\n","                        iris_norm, thresh=50)\n","                    template, mask_noise = encode_iris(\n","                        romv_img, noise_img, minw_length=18, mult=1, sigma_f=0.5)\n","\n","                    templates[i].append(template)\n","                    masks[i].append(mask_noise)\n","\n","                    # Matching\n","                    if len(templates[1]) > 0:\n","                        hd_raw = HammingDistance(\n","                            templates[i-1][j], masks[i-1][j], templates[i][j], masks[i][j])\n","                        results.append(hd_raw)\n","\n","            if len(results) == 2:\n","                if results == []:\n","                    continue\n","                if results[0] <= 0.48 and results[1] <= 0.48:\n","                    error += 1\n","                elif (results[0] <= 0.49 and results[1] <= 0.45) or (results[1] <= 0.49 and results[0] <= 0.45):\n","                    error += 1\n","                else:\n","                    continue\n","            else:\n","                error += 1\n","                print(f'Folder {folder} Image {num_img}: {results}')\n","        \n","        images.reset()\n","        \n","    return error/999*100"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_param(file = 'output3.csv', threshold = 0.48):\n","    TP = 0\n","    TN = 0\n","    FP = 0\n","    FN = 0\n","    df = pd.read_csv(file)\n","    for i in range(0, df.shape[1], 10):\n","        test = np.array(df.iloc[i:i + 10, i: i+10])\n","        temp1 = test <= threshold\n","        TP = TP + (temp1.sum() - 10)\n","        temp2 = test > threshold\n","        FN = FN + (temp2.sum())\n","\n","    df = np.array(df)\n","    df_temp1 = df <= threshold\n","    FP = df_temp1.sum() - df.shape[1] - TP\n","    df_temp2 = df > threshold\n","    TN = df_temp2.sum() - FN\n","\n","    return np.array([[TP, FP], [FN, TN]])\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from scipy import interpolate\n","from scipy.optimize import fsolve\n","test = np.linspace(0.25, 0.48, 40)\n","FAR = []\n","FRR = []\n","for i in test:\n","    \n","    temp = get_param(file = 'output3.csv', threshold=i)\n","    FAR.append( temp[0, 1]/sum(temp[0]))\n","    FRR.append( temp[1, 0]/sum(temp[1]))\n","\n","\n","far_spline = interpolate.splrep(test, FAR)\n","frr_spline = interpolate.splrep(test, FRR)\n","\n","\n","def difference(x):\n","    far_value = interpolate.splev(x, far_spline)\n","    frr_value = interpolate.splev(x, frr_spline)\n","    return far_value - frr_value\n","\n","initial_guess = 0\n","threshold_intersection = fsolve(difference, initial_guess)\n","print(f'threshold:{threshold_intersection[0]:.3f}, intersection:{interpolate.splev(threshold_intersection[0], far_spline):.3f}')\n","\n","FAR = np.array(FAR)\n","FRR = np.array(FRR)\n","\n","plt.figure(figsize=(8, 6), dpi=80)\n","plt.plot(test, FAR, label ='FAR')\n","plt.plot(test, FRR, label = 'FRR')\n","plt.title(\"FPR and FNR vs Threshold\")\n","plt.xlabel(\"Threshold\")\n","plt.ylabel(\"Rate\")\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"wstFeUv6xY09"},"source":["## <span style=\"color:orange\">*Main Program*</span>"]},{"cell_type":"markdown","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":329},"executionInfo":{"elapsed":9,"status":"error","timestamp":1679880319598,"user":{"displayName":"Oranus Kotsuwan","userId":"01427927832110327372"},"user_tz":-420},"id":"Z3jGuF1KxY09","outputId":"e377e35a-d900-4b14-c50b-fa9ea083166e"},"source":["#plot_prepro(img_num1=0, img_num2=40, plot_cols=2)\n","#plot_matching(img_num=0, compare_num=20)\n","#ham_dist = acc_plot(img_num=2, ref_img='CASIA-IrisV2/device1/0000/0000_000.bmp')\n","accuracy = 100 - acc_calc_demo37(ref_imgs=0, ref_img=0, test_fol=60, test_img=20)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":311,"status":"ok","timestamp":1679880788842,"user":{"displayName":"Oranus Kotsuwan","userId":"01427927832110327372"},"user_tz":-420},"id":"mLchd_HirjRw"},"outputs":[],"source":["# test_img = '/content/file_folder_drive'"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1679881112914,"user":{"displayName":"Oranus Kotsuwan","userId":"01427927832110327372"},"user_tz":-420},"id":"6CA0CltUs1vB"},"outputs":[],"source":["# path = '/content/gdrive/MyDrive/Iris Recognition/Share Iris/Iris-Dataset/CASIA-Iris-Thousand'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#plot_prepro(img_num1=0, img_num2=40, plot_cols=2)\n","#plot_matching(img_num=0, compare_num=20)\n","#ham_dist = acc_plot(img_num=2, ref_img='CASIA-IrisV2/device1/0000/0000_000.bmp')\n","accuracy = 100 - acc_calc_demo35(ref_imgs=0, ref_img=0, test_fol=2, test_img=2)  "]},{"cell_type":"markdown","metadata":{"colab":{"referenced_widgets":["c785c616ebdd470997bd13d9f9268f22","840b34c76bc3472ba5ed5a828d11c16b"]},"id":"Y_L98evtxY09","outputId":"6be424a8-5443-44bc-be04-a26cd502b34a"},"source":["#plot_prepro(img_num1=0, img_num2=40, plot_cols=2)\n","#plot_matching(img_num=0, compare_num=20)\n","#ham_dist = acc_plot(img_num=2, ref_img='CASIA-IrisV2/device1/0000/0000_000.bmp')\n","accuracy = 100 - acc_calc(ref_imgs=0, ref_img=0, test_fol=200, test_img=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CxRTfMvUxY09","outputId":"4ccb9f95-21f5-41a1-e9d1-452e6961c487"},"outputs":[],"source":["print(f'Accuracy: {round(accuracy)}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PPTBpTNUxY0-"},"outputs":[],"source":["# ham_dist.to_csv('Output/0000_000.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WshErBN-xY0-"},"outputs":[],"source":["ham_dist = pd.read_csv('output3.csv', index_col=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3eafl4pNxY0-","outputId":"91ada3e1-d577-4fce-cf7b-536f196a9c57"},"outputs":[],"source":["ham_dist.style.highlight_null().highlight_min(color='green').highlight_max(color='blue').applymap(lambda x: 'background-color: white' if x == 0 else '').format(\"{:.3f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zHl2A4l9xY0-","outputId":"073bbdd1-6ac7-4540-ebd8-4fbdcfb77e4f"},"outputs":[],"source":["ham_dist.style.applymap(lambda x: 'background-color: red' if x <= 0.48 else '').format(\"{:.3f}\").highlight_null()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"executionInfo":{"elapsed":10,"status":"error","timestamp":1679833301328,"user":{"displayName":"Oranus Kotsuwan","userId":"01427927832110327372"},"user_tz":-420},"id":"o-AoyONTxY0-","outputId":"b1d82991-addc-477e-a97a-b16f59c1dacc"},"outputs":[],"source":["mat_diff = ham_dist.iloc[:, 1:].copy()\n","mat_same = ham_dist.iloc[:, 0].copy()\n","\n","mat_diff = np.where(mat_diff > 0.46, 1, 0)\n","mat_same = np.where(mat_same <= 0.46, 1, 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JQInXowzxY0_","outputId":"db861718-37c0-44b8-9fb2-de91a30a630d"},"outputs":[],"source":["acc_diff = np.sum(mat_diff) / (mat_diff.shape[0] * mat_diff.shape[1])\n","acc_same = np.sum(mat_same) / mat_same.shape[0]\n","\n","print(f'Accuracy for different image: {acc_diff*100:.2f}%')\n","print(f'Accuracy for same image: {acc_same*100:.2f}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"28QUwugexY0_"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"},"vscode":{"interpreter":{"hash":"c91c7ded5a8abaf9a68f624d28a8ea7841420a8c072289ca0a8b1208415b2bb5"}}},"nbformat":4,"nbformat_minor":0}
